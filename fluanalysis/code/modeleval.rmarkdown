---
title: "Model Evaluation"
author: "Leah Lariscy"
editor: visual
format:
  html:
    toc: true
    toc-depth: 3
---


## Library packages


```{r, message=FALSE}
library(tidymodels)
library(tidyverse)
library(here)
library(dotwhisker)
```


## Load Data


```{r}
symptoms_fit <- readRDS(here("fluanalysis/data/processed_data/symptoms_clean.RDS"))
colnames(symptoms_fit) #quick look at data
```


## Data Split


```{r}
data_split <- initial_split(symptoms_fit, prop = 3/4) # 75% of data goes into training set

train_data <- training(data_split)
test_data <- testing(data_split)
```


## Model 1 fitting: all variables to predict nausea

### Define the model: logistic regression


```{r}
log_mod <- logistic_reg() %>% #model type is logistic regression 
  set_engine("glm") #engine set to generalized linear model
```


I am using a logistic regression here because the outcome of interest (Nausea Y/N) is categorical

### Create recipe


```{r}
recipe_nausea <- recipe(Nausea ~., data = train_data)
```


Nausea is the outcome and all other variables are predictors

### Create workflow: combine model definition and recipe


```{r}
nausea_log_wf <- workflow() %>% 
  add_model(log_mod) %>% #model definition 
  add_recipe(recipe_nausea) #model recipe
```


This will run a logistic regression on the flu data, predicting nausea using all other variables that we kept.

### Model fitting


```{r}
nausea_fit <- nausea_log_wf %>% 
  fit(data = train_data)

nausea_fit %>% extract_fit_parsnip() %>% 
  tidy()
```


### Model assessment on training data: ROC curve


```{r}
set.seed(626)
nausea_aug_test <- augment(nausea_fit, train_data)

nausea_aug_test %>% 
  roc_curve(truth = Nausea, .pred_Yes, event_level = "second") %>% 
  autoplot()

nausea_aug_test %>% roc_auc(truth = Nausea, .pred_Yes, 
                            event_level = "second")
```


ROC-AUC is ok

### Model assessment on testing data: ROC curve


```{r}
set.seed(626)
nausea_fit_test <- nausea_log_wf %>% 
  fit(data = test_data)

nausea_fit_test %>% extract_fit_parsnip() %>% 
  tidy()
nausea_aug_test2 <- augment(nausea_fit_test, test_data)

nausea_aug_test2 %>% 
  roc_curve(truth = Nausea, .pred_Yes, event_level = "second") %>% 
  autoplot()

nausea_aug_test2 %>% roc_auc(truth = Nausea, .pred_Yes, 
                            event_level = "second")
```


The testing data out-performed the training set

## Model 2 fitting: runny nose to predict nausea

### Create new recipe and workflow


```{r}
recipe_nausea2 <- recipe(Nausea ~RunnyNose, data = train_data) #only include runny nose

nausea_log_wf2 <- workflow() %>% 
  add_model(log_mod) %>% #model definition, use the same as Model 1
  add_recipe(recipe_nausea2) #model recipe
```


### Model fitting


```{r}
nausea_fit2 <- nausea_log_wf2 %>% 
  fit(data = train_data)

nausea_fit2 %>% extract_fit_parsnip() %>% 
  tidy()
```


### Model assessment on training data


```{r}
set.seed(626)
nausea_aug_test2 <- augment(nausea_fit2, train_data)

nausea_aug_test2 %>% 
  roc_curve(truth = Nausea, .pred_Yes, event_level = "second") %>% 
  autoplot()

nausea_aug_test2 %>% roc_auc(truth = Nausea, .pred_Yes, 
                            event_level = "second")
```


The ROC-AUC here is lower than Model 1

### Model assessment on testing data


```{r}
set.seed(626)
nausea_fit_test3 <- nausea_log_wf2 %>% 
  fit(data = test_data)

nausea_fit_test3 %>% extract_fit_parsnip() %>% 
  tidy()
nausea_aug_test3 <- augment(nausea_fit_test3, test_data)

nausea_aug_test3 %>% 
  roc_curve(truth = Nausea, .pred_Yes, event_level = "second") %>% 
  autoplot()

nausea_aug_test3 %>% roc_auc(truth = Nausea, .pred_Yes, 
                            event_level = "second")
```


The testing data is no different. Runny nose is likely not a good predictor of body temp.

