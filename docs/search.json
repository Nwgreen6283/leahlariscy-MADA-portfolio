[
  {
    "objectID": "tidytuesday_exercise.html",
    "href": "tidytuesday_exercise.html",
    "title": "Tidy Tuesday Exercise",
    "section": "",
    "text": "Introduction\n\nThis is the TidyTuesday data set for February 14th, 2023. Data consist of observations pertaining to age differences in couples from Hollywood movies spanning almost an entire century.\n\n\n\nLoading packages and setting figure size\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.0     ✔ readr     2.1.4\n✔ forcats   1.0.0     ✔ stringr   1.5.0\n✔ ggplot2   3.4.1     ✔ tibble    3.1.8\n✔ lubridate 1.9.2     ✔ tidyr     1.3.0\n✔ purrr     1.0.1     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the \u001b]8;;http://conflicted.r-lib.org/\u0007conflicted package\u001b]8;;\u0007 to force all conflicts to become errors\n\nlibrary(skimr)\nlibrary(ggpmisc)\n\nLoading required package: ggpp\n\nAttaching package: 'ggpp'\n\nThe following object is masked from 'package:ggplot2':\n\n    annotate\n\nknitr::opts_chunk$set(fig.width=10, fig.height=8) \n\n\n\nData loading\nFollow the TidyTuesday instructions for 2023-02-14\n\nage_gaps <- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2023/2023-02-14/age_gaps.csv')\n\nRows: 1155 Columns: 13\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (6): movie_name, director, actor_1_name, actor_2_name, character_1_gend...\ndbl  (5): release_year, age_difference, couple_number, actor_1_age, actor_2_age\ndate (2): actor_1_birthdate, actor_2_birthdate\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\n\nData exploration\n\nskim(age_gaps)\n\n\nData summary\n\n\nName\nage_gaps\n\n\nNumber of rows\n1155\n\n\nNumber of columns\n13\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\ncharacter\n6\n\n\nDate\n2\n\n\nnumeric\n5\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: character\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nempty\nn_unique\nwhitespace\n\n\n\n\nmovie_name\n0\n1\n2\n43\n0\n830\n0\n\n\ndirector\n0\n1\n3\n31\n0\n510\n0\n\n\nactor_1_name\n0\n1\n6\n22\n0\n567\n0\n\n\nactor_2_name\n0\n1\n7\n27\n0\n647\n0\n\n\ncharacter_1_gender\n0\n1\n3\n5\n0\n2\n0\n\n\ncharacter_2_gender\n0\n1\n3\n5\n0\n2\n0\n\n\n\nVariable type: Date\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nmedian\nn_unique\n\n\n\n\nactor_1_birthdate\n0\n1\n1889-04-16\n1996-06-01\n1964-10-03\n562\n\n\nactor_2_birthdate\n0\n1\n1906-10-06\n1996-11-11\n1974-07-30\n640\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\nrelease_year\n0\n1\n2000.80\n16.37\n1935\n1997\n2004\n2012\n2022\n▁▁▁▆▇\n\n\nage_difference\n0\n1\n10.42\n8.51\n0\n4\n8\n15\n52\n▇▃▂▁▁\n\n\ncouple_number\n0\n1\n1.40\n0.75\n1\n1\n1\n2\n7\n▇▁▁▁▁\n\n\nactor_1_age\n0\n1\n40.64\n10.42\n18\n33\n39\n47\n81\n▂▇▅▂▁\n\n\nactor_2_age\n0\n1\n30.21\n7.50\n17\n25\n29\n34\n68\n▇▇▂▁▁\n\n\n\n\n\nBy using skim(), I can see many interesting things about the data:\n\nThe mean age difference between couples is about 10 years.\nThere are 830 unique movies listed, spanning from 1935 to 2022, with most movies only having one couple each.\nSome actor names are repeated upwards of 20 times, showing that they have been involved in multiple couples.\n\n\n\nIdeas for analysis\n\nI will start by designating sexuality of each couple into three groups (straight, gay, sapphic) because I am interested to see how many queer couples there are. If there are enough, we could look at age gap differences between each group.\nI will then determine which gender is the oldest in each pair because I hypothesize that men will be older more of the time.\nI will start with these two questions for now and see where they take me\n\n\n\nMutate data\n\nClassifying sexuality of each couple\nHere I will create a new variable called sexuality based on whether each couple is of same or opposite gender, creating three labels for these relationships: straight (man & woman), gay (man & man), and sapphic (woman & woman)\nI will also look at how many observations there are for each sexuality.\n\nage_gaps_sexuality <- age_gaps %>% \n  mutate(sexuality = case_when(character_1_gender == 'man' & character_2_gender == 'woman' ~ 'straight',\n                               character_1_gender == 'man' & character_2_gender == 'man' ~ 'gay',\n                               character_1_gender == 'woman' & character_2_gender == 'woman' ~ 'sapphic',\n                               character_2_gender == 'man' & character_1_gender == 'woman' ~ 'straight',\n                               character_2_gender == 'man' & character_1_gender == 'man' ~ 'gay',\n                               character_2_gender == 'woman' & character_1_gender == 'woman' ~ 'sapphic'))\nsexuality_count <- age_gaps_sexuality %>% count(sexuality)\nsexuality_count <- sexuality_count %>% mutate(proportion = n/sum(n))\ntibble(sexuality_count)\n\n# A tibble: 3 × 3\n  sexuality     n proportion\n  <chr>     <int>      <dbl>\n1 gay          12    0.0104 \n2 sapphic      11    0.00952\n3 straight   1132    0.980  \n\n\nHere, you see that 98% of couples in this data set can be defined as heterosexual.\n\n\nCounting how many times each gender is older than their partner\nHere, I will count the number of times each gender is older and then calculate that proportion.\n\nolder_count <- age_gaps %>% count(character_1_gender)\nolder_count <- older_count %>% mutate(proportion = n/sum(n))\ntibble(older_count)\n\n# A tibble: 2 × 3\n  character_1_gender     n proportion\n  <chr>              <int>      <dbl>\n1 man                  941      0.815\n2 woman                214      0.185\n\n\nAs you can see here, men in Hollywood are much more likely to be older than their partner than women are. In this data set, men were older than their partner 80% of the time.\n\n\n\nData visualization\n\nDifference in average age gaps between straight, gay, and sapphic couples\n\nage_gaps_sexuality %>% ggplot(aes(sexuality, age_difference, color = sexuality)) +\n  geom_boxplot() +\n  ggthemes::theme_fivethirtyeight()\n\n\n\n\nIt appears that gay couples have a higher average age gap than other sexualities, but remember that they make up only 1% of observations.\n\n\nNumber of same-movie couples throughout the years\n\nage_gaps_sexuality %>% ggplot(aes(y = couple_number, x = release_year, fill = sexuality)) + \n  geom_bar(stat = \"identity\") +\n  scale_x_continuous(name = \"Year Released\", breaks = seq(1930,2022,10)) +\n  ggthemes::theme_fivethirtyeight()\n\n\n\n\nOnly straight couples were documented in Hollywood prior to the 1990s. Queer couplings began to be documented in the 1990s and early 2000s, but still make up a small portion of couples which we saw earlier. We can also note that queer couplings started to pop up around the time that couple numbers in Hollywood dramatically increased in the late 1990s.\n\n\nDifference in age gaps between older men and women\n\nage_gaps %>% ggplot(aes(character_1_gender, age_difference, color = character_1_gender)) +\n  geom_boxplot() +\n  scale_color_manual(values = c('#00C4D4', '#634490')) +\n   ggthemes::theme_fivethirtyeight()\n\n\n\n\nWithin Hollywood, older men tend to have a higher age gap with their partner than older women do.\n\n\nDifference in age gaps between younger men and women\n\nage_gaps %>% ggplot(aes(character_2_gender, age_difference, color = character_2_gender)) +\n  geom_boxplot() +\n  scale_color_manual(values = c('#00C4D4', '#634490')) +\n   ggthemes::theme_fivethirtyeight()\n\n\n\n\nWithin Hollywood, younger men tend to have a smaller age gap with their partners compared to younger women who have a larger average age gap.\n\n\nLinear regression of age vs age gap between men and women\n\nage_gaps %>% ggplot(aes(actor_1_age, age_difference, color = character_1_gender)) +\n  stat_poly_line() +\n  stat_poly_eq() +\n  geom_jitter() +\n  scale_color_manual(name = \"Gender\", values = c('#00C4D4', '#634490')) +\n  ggthemes::theme_fivethirtyeight() +\n  labs(title = \"Linear model of older partner's age vs. relationship age gap\")\n\n\n\n\nMen in Hollywood who date younger people (most of them) are more likely to have an increased age gap in their relationships as they age, more so than women.\n\nage_gaps %>% ggplot(aes(actor_2_age, age_difference, color = character_2_gender)) +\n  stat_poly_line() +\n  stat_poly_eq() +\n  geom_jitter() +\n  scale_color_manual(values = c('#00C4D4', '#634490')) +\n  ggthemes::theme_fivethirtyeight() +\n  labs(title = \"Linear model of younger parter's age vs. relationship age gap\")\n\n\n\n\nWe do not see this same trend with the younger partners. This makes sense partly because as someone gets older, there are going to be less people older than them and eventually they will have to be with someone their own age.\nThere are less men who are younger than their partner than men who are older, and there seems to be no indication that their age is a determining factor in their relationship age gap.\nThere are far more women who are younger than their partner than men, and overall it appears there are less women in couples past the age of 40, compared to the first scatter plot where men are in couples well past their 40s.\n\n\n\nDiscussion and conclusions\nWhat I learned from looking at this data of Hollywood couples on the same movie set:\n\n98% of documented couples were heterosexual\nMen (~80%) were more likely to date someone younger than them then women (20%) were\nOlder men had a higher average age gap in their relationships (10 years vs 2-3 years in women), meaning they were more likely to date women much younger than them than older women were to date much younger men\nOlder partners of both genders showed an increase in relationship age gaps as their own age increased, although this was much more pronounced for men, meaning that as these men aged, they continued to date young women\n\n\nFrom this data exploration, I have concluded that on average, men in Hollywood tend to date much younger women than themselves. They also continue to date much younger women as they age. I would also be interested in looking at the average age of all men recorded vs the average age of women because I have a feeling that men on average are older.\nTo conclude, and to quote Taylor Swift, “I’ll get older, but your lovers stay my age”."
  },
  {
    "objectID": "aboutme.html",
    "href": "aboutme.html",
    "title": "About me",
    "section": "",
    "text": "My name is Leah Lariscy and I have a BS in Environmental Health and am now a first year PhD student in Environmental Health. My advisors are Travis Glenn and Erin Lipp and my research involves molecular detection in wastewater, mainly viral pathogens such as SARS-CoV-2, Mpox, and RSV. I also have some experience in many microbiology techniques, as well as some bioinformatics."
  },
  {
    "objectID": "aboutme.html#experience",
    "href": "aboutme.html#experience",
    "title": "About me",
    "section": "Experience",
    "text": "Experience\nI first began working with R studio at the beginning of 2022, although I was mostly just trying to learn from other grad students and self-teach. In the Fall of 2022 I started my graduate career by taking EPID 7500, an intro to coding in R course, which allowed me to get familiar with R studio and get comfortable doing simple analysis. I also started running the wastewater surveillance script for the Lipp Lab’s COVID-19 surveillance website in the Fall. This involved raw data from qPCR outputs which I used to estimate copies per liter of SARS-CoV-2 viral particles in Athens-Clarke County wastewater influent."
  },
  {
    "objectID": "aboutme.html#my-goals-for-the-class",
    "href": "aboutme.html#my-goals-for-the-class",
    "title": "About me",
    "section": "My goals for the class",
    "text": "My goals for the class\nI have been looking forward to taking this class for a while now as I’ve heard so many great things! My hope is that this class will give me more tools to become a better researcher, such as creating reproducible workflows and doing more complicated statistical analysis on my own data."
  },
  {
    "objectID": "aboutme.html#a-picture-of-me",
    "href": "aboutme.html#a-picture-of-me",
    "title": "About me",
    "section": "A picture of me!",
    "text": "A picture of me!"
  },
  {
    "objectID": "aboutme.html#lipp-lab-covid-19-surveillance-website",
    "href": "aboutme.html#lipp-lab-covid-19-surveillance-website",
    "title": "About me",
    "section": "Lipp Lab COVID-19 Surveillance Website",
    "text": "Lipp Lab COVID-19 Surveillance Website\nCOVID-19 Dashboard\nHere is the surveillance site that I described above, which shows you a graph of wastewater viral levels compared to clinical cases of COVID-19 from July 2020 to December 2022. Since I only have experience working on the data analysis side of this, I am also interested in learning to create websites similar to this for my continued detection work with other pathogens."
  },
  {
    "objectID": "visualization_exercise.html",
    "href": "visualization_exercise.html",
    "title": "Visualization Exercise",
    "section": "",
    "text": "library(tidyverse) #for data cleaning\n\n── Attaching packages ─────────────────────────────────────── tidyverse 1.3.2 ──\n✔ ggplot2 3.4.0     ✔ purrr   1.0.1\n✔ tibble  3.1.8     ✔ dplyr   1.0.9\n✔ tidyr   1.2.0     ✔ stringr 1.4.1\n✔ readr   2.1.2     ✔ forcats 0.5.2\n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\n\nlibrary(here) #for setting file paths\n\nhere() starts at /Users/leahlariscy/Desktop/MADA2023/leahlariscy-MADA-portfolio\n\nlibrary(ggthemes) #for loading ggplot themes\nlibrary(skimr) #for skimming data sets\n\n\n\n\n\nknitr::opts_chunk$set(fig.width=10, fig.height=8) \n\n\n\n\nYou will see that the data set includes the following variables -> Owner,Team,League, Recipient, Amount, Election Year, and Party\n\nhere()\n\n[1] \"/Users/leahlariscy/Desktop/MADA2023/leahlariscy-MADA-portfolio\"\n\ndonation <- read_csv(\"data/sports-political-donations/sports-political-donations.csv\")\n\nRows: 2798 Columns: 7\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (6): Owner, Team, League, Recipient, Amount, Party\ndbl (1): Election Year\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nskim(donation)\n\n\nData summary\n\n\nName\ndonation\n\n\nNumber of rows\n2798\n\n\nNumber of columns\n7\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\ncharacter\n6\n\n\nnumeric\n1\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: character\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nempty\nn_unique\nwhitespace\n\n\n\n\nOwner\n0\n1\n9\n43\n0\n158\n0\n\n\nTeam\n0\n1\n9\n59\n0\n115\n0\n\n\nLeague\n0\n1\n3\n14\n0\n16\n0\n\n\nRecipient\n0\n1\n3\n96\n0\n1274\n0\n\n\nAmount\n0\n1\n3\n10\n0\n244\n0\n\n\nParty\n0\n1\n3\n33\n0\n7\n0\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\nElection Year\n0\n1\n2017.93\n1.6\n2016\n2016\n2018\n2020\n2020\n▇▁▇▁▇\n\n\n\n\n\n\n\n\nThese are the following steps I took to prepare the data.\n\nFilter for rows containing only the 6 leagues, leaving out ones that were cross-listed among many leagues. This removed a large amount of the data, meaning that a majority of team owners own multiple teams across various leagues.\nFilter for rows containing only democrat or republican, leaving out bipartisan donations. I would have left these in but I had issuing renaming all variations to just bipartisan.\nParse the numerical values from Amount so it can then act as a numerical.\nGroup by League, Election Year, and Party\nSum the Amount of each group to find the total dollar amount of donations from each of the 6 leagues to each of the two parties in a given year.\nUngroup. Data is now ready to plot.\n\n\ndonation_clean <- donation %>% \n  filter(League ==c(\"MLB\",\"NASCAR\",\"NBA\",\"NFL\",\"NHL\",\"WNBA\")) %>% \n \n  filter(Party ==c(\"Democrat\",\"Republican\")) %>% \n  \n  mutate(Amount = parse_number(Amount)) %>% \n  \n  group_by(League,`Election Year`,Party) %>% \n  \n  summarise(party_donations = sum(Amount)) %>% \n  \n  ungroup() \n\nWarning in League == c(\"MLB\", \"NASCAR\", \"NBA\", \"NFL\", \"NHL\", \"WNBA\"): longer\nobject length is not a multiple of shorter object length\n\n\nWarning in Party == c(\"Democrat\", \"Republican\"): longer object length is not a\nmultiple of shorter object length\n\n\n`summarise()` has grouped output by 'League', 'Election Year'. You can override\nusing the `.groups` argument.\n\nskim(donation_clean)\n\n\nData summary\n\n\nName\ndonation_clean\n\n\nNumber of rows\n32\n\n\nNumber of columns\n4\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\ncharacter\n2\n\n\nnumeric\n2\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: character\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nempty\nn_unique\nwhitespace\n\n\n\n\nLeague\n0\n1\n3\n6\n0\n6\n0\n\n\nParty\n0\n1\n8\n10\n0\n2\n0\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\nElection Year\n0\n1\n2018.0\n1.68\n2016\n2016\n2018\n2020\n2020\n▇▁▇▁▇\n\n\nparty_donations\n0\n1\n138422.2\n379996.99\n1600\n9250\n18450\n65300\n1808600\n▇▁▁▁▁\n\n\n\n\n\n\n\n\n\ndonation_plot <- donation_clean %>%\nggplot(aes(fill=Party, y=party_donations, x=`Election Year`)) +\n\n  geom_bar(position = \"fill\", stat = \"identity\", color = \"white\") + #basic geometry of plot, bar plot\n\n  facet_wrap(as.factor(donation_clean$League)) + #plot by individual League\n\n  scale_fill_manual(name=\"DONATIONS TO\", values=c(\"#00A5E3\", \"#CC0000\"), #looked up hexcodes on google \n  labels=c(\"DEMOCRATS\",\"REPUBLICANS\")) + #fill colors in correct order\n\n  theme_fivethirtyeight() + #theme from fivethirtyeight website\n\n  scale_x_continuous(breaks = seq(2016,2020,2)) + #2 year breaks between 2016 & 2020\n\n  labs(title = \"Across leagues, majority of donations go to Republicans\",\n  subtitle = \"Share of donations from team owners in six leagues, per year, league and party\") +\n\n  theme(legend.title = element_text(face = \"bold\", size = 16),\n  legend.text = element_text(size = 16),\n  plot.title.position = \"plot\",\n  plot.title = element_text(face = \"bold\", size = 24),\n  plot.subtitle = element_text(size = 18),\n  legend.position = \"top\",\n  axis.text.x = element_text(size = 14))\n  donation_plot\n\n\n\n\nYou will notice that the proportions on my plot are slightly different from the original. This is because I excluded all cross-listed league affiliations (for the sake of time, but in the future I would like to be able to parse these out into individual observations). I also excluded bipartisan donations and NAs because I was having trouble renaming these all to bipartisan. I would also like to work on this, as I would like to be able to re-create this chart more accurately.\nI also had some formatting issues that I couldn’t quite work out on my own. For one, I could not figure out how to change the size of the facet labels. I also struggled to find a way to change the y-axis tick labels to be percentages like on the original."
  },
  {
    "objectID": "coding_exercise.html",
    "href": "coding_exercise.html",
    "title": "R Coding Exercise",
    "section": "",
    "text": "Load required packages and data here\nSubset the data, only keeping data from Africa\nPlot the data here"
  },
  {
    "objectID": "coding_exercise.html#this-section-added-by-sara-benist",
    "href": "coding_exercise.html#this-section-added-by-sara-benist",
    "title": "R Coding Exercise",
    "section": "This section added by Sara Benist",
    "text": "This section added by Sara Benist\n###Load the packages\n\nlibrary(dslabs)\nlibrary(tidyverse)\nlibrary(dplyr)\nlibrary(broom)\n\n\nSubsetting data\nI want to continue to explore the data related to African countries, specifically how gdp and infant mortality relates to fertility.\n\n#subset African countries\nafricadata <- filter(gapminder, continent == \"Africa\")\n\n#select only the `gdp` and `fertility` columns and assign to `gdpfert`\ngdpfert <- africadata %>% select(gdp, fertility)\n\n#select only the `fertility` and `infant_mortality` columns and assign to `fertmort`\nfertmort <- africadata %>% select(fertility, infant_mortality)\n\n\n\nPlotting the data\nNext, I wanted to look at the plots for the two new datasets. For both gdpfert and fertmort, I plotted the data points using geom_point() and geom_smooth() to produce a scatter plot with a smoothed line over the data. The smoothed line helps visualize patterns in the plot.\n\n#produce scatter plot with smooth line; x = gdp, y = fertility\n#x-axis log transformed for gdp data\nggplot(gdpfert, aes(gdp, fertility))+\n  geom_point() + \n  geom_smooth()+\n  scale_x_continuous(trans = \"log\")\n\n`geom_smooth()` using method = 'gam' and formula = 'y ~ s(x, bs = \"cs\")'\n\n\nWarning: Removed 637 rows containing non-finite values (`stat_smooth()`).\n\n\nWarning: Removed 637 rows containing missing values (`geom_point()`).\n\n\n\n\n\nWe can see a distinct negative correlation with fertility after the GDP of a country reaches above approx. 9.7 billion dollars. Note that most African countries have a GDP between 485 million and $9.7 billion dollars where the line fluctuates around 6 children per woman.\n\n#produce scatter plot with smooth line; x = fertility, y = infant_mortality\nggplot(fertmort, aes(fertility, infant_mortality)) +\n  geom_point()+\n  geom_smooth()\n\n`geom_smooth()` using method = 'gam' and formula = 'y ~ s(x, bs = \"cs\")'\n\n\nWarning: Removed 226 rows containing non-finite values (`stat_smooth()`).\n\n\nWarning: Removed 226 rows containing missing values (`geom_point()`).\n\n\n\n\n\nHere, fertility and infant mortality are positively correlated until approximately 7 children per woman or 125 infants deaths per 1000.\n\n\nLinear modeling\nI would like to consider a linear model predicting fertility from GDP and infant mortality for African countries. The glm() function will be used to create a linear model for this scenario. The tidy() function from the broom package produces the summary of the model.\n\nfit3 <- glm(fertility ~ gdp + infant_mortality, data = africadata)\n\ntidy(fit3)\n\n# A tibble: 3 × 5\n  term              estimate std.error statistic   p.value\n  <chr>                <dbl>     <dbl>     <dbl>     <dbl>\n1 (Intercept)       3.91e+ 0  5.49e- 2      71.2 0        \n2 gdp              -1.41e-11  9.62e-13     -14.7 1.45e- 46\n3 infant_mortality  2.18e- 2  4.99e- 4      43.6 4.58e-300\n\n\nBoth GDP and infant mortality has a statistically significant affect on fertility (p-values > 0.001). GDP has an extremely small negative effect on fertility (slope = -1.411e-11), and infant mortality has a small positive effect (slope = 2.176e-2)."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Leah Lariscy’s website and data analysis portfolio",
    "section": "",
    "text": "EPID 8060 (MADA)\n\nPlease use the Menu Bar above to look at completed exercises."
  },
  {
    "objectID": "data_analysis_exercise.html",
    "href": "data_analysis_exercise.html",
    "title": "Data Analysis Exercise",
    "section": "",
    "text": "library(tidyverse)\n\n── Attaching packages ─────────────────────────────────────── tidyverse 1.3.2 ──\n✔ ggplot2 3.4.0      ✔ purrr   1.0.1 \n✔ tibble  3.1.8      ✔ dplyr   1.0.10\n✔ tidyr   1.2.1      ✔ stringr 1.5.0 \n✔ readr   2.1.3      ✔ forcats 0.5.2 \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\n\nlibrary(lubridate)\n\nLoading required package: timechange\n\nAttaching package: 'lubridate'\n\nThe following objects are masked from 'package:base':\n\n    date, intersect, setdiff, union"
  },
  {
    "objectID": "data_analysis_exercise.html#data-description",
    "href": "data_analysis_exercise.html#data-description",
    "title": "Data Analysis Exercise",
    "section": "Data description",
    "text": "Data description\nThis dataset was accessed from the Bacteria, Enterics, Amoeba, and Mycotics (BEAM) Dashboard, which houses data collected by the System for Enteric Disease Response, Investigation, and Coordination (SEDRIC). The data points represent pathogens isolated from infected individuals, namely Salmonella, E. Coli, Shigella, and Campylobacter bacteria.\nYou can access the BEAM Dashboard here.\n\nbeam_raw <- read_csv(\"data_analysis_exercise/data/raw_data/BEAM_Dashboard_Report_Data.csv\")\n\nRows: 128342 Columns: 10\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (4): State, Source, Pathogen, Serotype/Species\ndbl (6): Year, Month, Number_of_isolates, Outbreak_associated_isolates, New_...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message."
  },
  {
    "objectID": "data_analysis_exercise.html#data-cleaning",
    "href": "data_analysis_exercise.html#data-cleaning",
    "title": "Data Analysis Exercise",
    "section": "Data cleaning",
    "text": "Data cleaning\nBegin by combining the Year and Month variables into one Date variable, then select for variables of interest and rename them. Lastly, change all NAs to 0s where necessary.\n\nbeam_clean <- beam_raw %>% mutate(date = make_date(year=Year, month=Month, day=1)) %>% \n\n  select(c(date, state=State, source=Source, pathogen=Pathogen, species=`Serotype/Species`,\n       n_isolates=Number_of_isolates, n_outbreak_associated=Outbreak_associated_isolates)) %>% \n\n  mutate(n_isolates = ifelse(is.na(n_isolates), 0, n_isolates), \n       n_outbreak_associated = ifelse(is.na(n_outbreak_associated), 0, n_outbreak_associated))\n\nprint(beam_clean)\n\n# A tibble: 128,342 × 7\n   date       state source pathogen    species                   n_iso…¹ n_out…²\n   <date>     <chr> <chr>  <chr>       <chr>                       <dbl>   <dbl>\n 1 2017-09-01 TX    Stool  Escherichia Shigella Flexneri Seroty…       1       0\n 2 2017-09-01 TX    Stool  Escherichia sonnei                         14       0\n 3 2017-09-01 TX    Stool  Salmonella  Agbeni                          1       0\n 4 2017-09-01 TX    Stool  Salmonella  Agona                           5       0\n 5 2017-09-01 TX    Stool  Salmonella  Altona                          1       0\n 6 2017-09-01 TX    Stool  Salmonella  Anatum                          2       2\n 7 2017-09-01 TX    Stool  Salmonella  Anatum, Newington, Minne…       2       0\n 8 2017-09-01 TX    Stool  Salmonella  Baildon                         1       0\n 9 2017-09-01 TX    Stool  Salmonella  Bareilly                        2       0\n10 2017-09-01 TX    Stool  Salmonella  Berta                           2       0\n# … with 128,332 more rows, and abbreviated variable names ¹​n_isolates,\n#   ²​n_outbreak_associated"
  },
  {
    "objectID": "data_analysis_exercise.html#save-cleaned-data-to-rds-file",
    "href": "data_analysis_exercise.html#save-cleaned-data-to-rds-file",
    "title": "Data Analysis Exercise",
    "section": "Save cleaned data to RDS file",
    "text": "Save cleaned data to RDS file\n\nsaveRDS(beam_clean, \"data_analysis_exercise/data/raw_data/BEAM_Report_clean.RDS\")"
  },
  {
    "objectID": "data_analysis_exercise.html#read-in-rds-file",
    "href": "data_analysis_exercise.html#read-in-rds-file",
    "title": "Data Analysis Exercise",
    "section": "Read in RDS file",
    "text": "Read in RDS file\n\n#read_rds(\"data_analysis_exercise/data/raw_data/BEAM_Report_clean.RDS\")"
  },
  {
    "objectID": "data_analysis_exercise.html#exploratory-analysis",
    "href": "data_analysis_exercise.html#exploratory-analysis",
    "title": "Data Analysis Exercise",
    "section": "Exploratory analysis",
    "text": "Exploratory analysis\nI would be interested in grouping by pathogen and exploring trends across states. I’d also like to see which pathogens are more likely to be associated with outbreaks."
  },
  {
    "objectID": "hello.html",
    "href": "hello.html",
    "title": "Penguins, meet Quarto!",
    "section": "",
    "text": "Quarto enables you to weave together content and executable code into a finished document. To learn more about Quarto see https://quarto.org."
  },
  {
    "objectID": "hello.html#meet-the-penguins",
    "href": "hello.html#meet-the-penguins",
    "title": "Penguins, meet Quarto!",
    "section": "Meet the penguins",
    "text": "Meet the penguins\n\nThe penguins data from the palmerpenguins package contains size measurements for 344 penguins from three species observed on three islands in the Palmer Archipelago, Antarctica.\nThe plot below shows the relationship between flipper and bill lengths of these penguins."
  },
  {
    "objectID": "data_analysis_exercise.html#this-section-was-added-by-kimberly-perez",
    "href": "data_analysis_exercise.html#this-section-was-added-by-kimberly-perez",
    "title": "Data Analysis Exercise",
    "section": "This section was added by Kimberly Perez",
    "text": "This section was added by Kimberly Perez\n#Reading in RDS\nHere I will use the readRDS() function to load Leah’s cleaned BEAM data.\n\n#Utilize readRDS for this task\nnewbc<-readRDS(\"data_analysis_exercise/data/raw_data/BEAM_Report_clean.RDS\")"
  },
  {
    "objectID": "data_analysis_exercise.html#state-selection",
    "href": "data_analysis_exercise.html#state-selection",
    "title": "Data Analysis Exercise",
    "section": "State selection",
    "text": "State selection\nHere I will use the filter function to select seven states\n\nbc<- beam_clean %>%\n  filter(state == 'GA' | state == 'AZ' | state == 'CA'| state == 'ND' | state == 'NY'| state == 'OR' | state == 'KS')\n\n\nPathogen Source by State\n\nggplot(bc, aes(state, pathogen, colour = source)) + geom_count(show.legend=T) +\n  labs(y=\"Pathogen\", \n       x=\"State\", \n       title=\"Pathogen Source by State (2017-2022)\")"
  },
  {
    "objectID": "data_analysis_exercise.html#outbreak-by-state-and-pathogen",
    "href": "data_analysis_exercise.html#outbreak-by-state-and-pathogen",
    "title": "Data Analysis Exercise",
    "section": "Outbreak by state and pathogen",
    "text": "Outbreak by state and pathogen\n\ntheme_set(theme_bw())  \nbc1 <- ggplot(bc, aes(state, n_outbreak_associated)) + \n  labs(title=\"Pathogen Associated with Outbreak by State (2017-2022)\",\n      y= \"Number of Outbreaks\",\n      x= \"State\")\n\nbc1 + geom_jitter(aes(col=pathogen, size=n_outbreak_associated)) + \n  geom_smooth(aes(col=pathogen), method=\"lm\", se=F)\n\n`geom_smooth()` using formula = 'y ~ x'"
  },
  {
    "objectID": "data_analysis_exercise.html#density-of-each-pathogen-over-time",
    "href": "data_analysis_exercise.html#density-of-each-pathogen-over-time",
    "title": "Data Analysis Exercise",
    "section": "Density of each pathogen over time",
    "text": "Density of each pathogen over time\nThis website seems to be a comprehensive resource for data visualization. I found the density plot and wanted to try my hand at recreating it. Below is my attempt.\n\nbcc <- ggplot(bc, aes(date))\nbcc + geom_density(aes(fill=factor(pathogen)), alpha=0.8) + \n    labs(title=\"Pathogen density from (2017-2022)\", \n         x=\"Year\",\n         y=\"Density\",\n         fill=\"Pathogen\") + ylim (0,0.001)"
  },
  {
    "objectID": "data_analysis_exercise.html#outbreak-by-state-and-pathogen-2017-2022",
    "href": "data_analysis_exercise.html#outbreak-by-state-and-pathogen-2017-2022",
    "title": "Data Analysis Exercise",
    "section": "Outbreak by State and Pathogen (2017-2022)",
    "text": "Outbreak by State and Pathogen (2017-2022)\n\ntheme_set(theme_bw())  \nbc1 <- ggplot(bc, aes(state, n_outbreak_associated)) + \n  labs(title=\"Pathogen Associated with Outbreak by State (2017-2022) by State\",\n      y= \"Number of Outbreaks\",\n      x= \"State\")\n\nbc1 + geom_jitter(aes(col=pathogen, size=n_outbreak_associated)) + \n  geom_smooth(aes(col=pathogen), method=\"lm\", se=F)\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\nbc_1<- bc %>% \n  group_by(date, pathogen, state, n_outbreak_associated) %>% \n  mutate(count=n()) %>% \n  ungroup() %>%  \n  select(-c(n_isolates, species, source))\n\nbc_1 %>% ggplot() +geom_line(\n  aes(x = date,\n      y = n_outbreak_associated,\n      color = pathogen,\n      linetype = state)) +\n  theme_bw() +\n  labs(x = \"Year\",\n       y = \"Number of Outbreaks (Associated with Pathogen)\",\n       color= \"Pathogen\",\n       linetype=\"State\",\n       title = \"Pathogen Associated with an Outbreak by State (2017-2022)\") +\n  theme(plot.title = element_text(hjust = 0.6))\n\n\n\n\nSalmonella and Ecoli look to be the pathogens that are associated with the largest number of outbreaks among these four states.\n\nPathogen Source by State\nHave you ever wondered what laboratories isolate pathogens from? Let’s explore the possibilities below!\n\n#Plotting \nggplot(bc, aes(state, pathogen, colour = source)) + geom_count(show.legend=T) +\n  labs(y=\"Pathogen\", \n       x=\"State\", \n       title=\"Pathogen Source by State (2017-2022)\")\n\n\n\n\nFrom the visualization above, it looks like most labs are able to isolate pathogens from stool samples, however, there may be variation by state!"
  },
  {
    "objectID": "data_analysis_exercise.html#a-bit-more-data-wrangling",
    "href": "data_analysis_exercise.html#a-bit-more-data-wrangling",
    "title": "Data Analysis Exercise",
    "section": "A bit more data wrangling",
    "text": "A bit more data wrangling\nI will now select four states to analyze\n\n#Creating a new dataframe with four selected states\nbc<- newbc %>%\n  filter(state == 'GA'  | state == 'CA'| state == 'ND' | state == 'OR' )"
  },
  {
    "objectID": "data_analysis_exercise.html#potentially-helpful-resource",
    "href": "data_analysis_exercise.html#potentially-helpful-resource",
    "title": "Data Analysis Exercise",
    "section": "Potentially helpful resource",
    "text": "Potentially helpful resource\nThis website seems to be a helpful resource for data visualization. I found some interesting visualizations and hope to practice utilizing several.\n```"
  },
  {
    "objectID": "data_analysis_exercise.html#visualizing-outbreak-by-state-and-pathogen-2017-2022-in-two-ways",
    "href": "data_analysis_exercise.html#visualizing-outbreak-by-state-and-pathogen-2017-2022-in-two-ways",
    "title": "Data Analysis Exercise",
    "section": "Visualizing Outbreak by State and Pathogen (2017-2022) in two ways…",
    "text": "Visualizing Outbreak by State and Pathogen (2017-2022) in two ways…\n\ntheme_set(theme_bw())  \n\n#Visualizing the data...\nbc1 <- ggplot(bc, aes(state, n_outbreak_associated)) + \n  labs(title=\"Pathogen Associated with Outbreak by State (2017-2022) by State\",\n      y= \"Number of Outbreaks\",\n      x= \"State\")\n\nbc1 + geom_jitter(aes(col=pathogen, size=n_outbreak_associated)) + \n  geom_smooth(aes(col=pathogen), method=\"lm\", se=F)\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n#Another way to visualize the data...\nbc %>% \n  ggplot() +geom_line(\n  aes(x = date,\n      y = n_outbreak_associated,\n      color = pathogen,\n      linetype = state)) +\n  theme_bw() +\n  labs(x = \"Year\",\n       y = \"Number of Outbreaks (Associated with Pathogen)\",\n       color= \"Pathogen\",\n       linetype=\"State\",\n       title = \"Pathogen Associated with an Outbreak by State (2017-2022)\") +\n  theme(plot.title = element_text(hjust = 0.6))\n\n\n\n\nSalmonella and Ecoli look to be the pathogens that are associated with the largest number of outbreaks among these four states.\n\nPathogen Source by State\nHave you ever wondered what laboratories isolate pathogens from? Let’s explore the possibilities below!\n\n#Plotting \nggplot(bc, aes(state, pathogen, colour = source)) + geom_count(show.legend=T) +\n  labs(y=\"Pathogen\", \n       x=\"State\", \n       title=\"Pathogen Source by State (2017-2022)\")\n\n\n\n\nFrom the visualization above, it looks like most labs are able to isolate pathogens from stool samples, however, there may be variation by state!"
  },
  {
    "objectID": "visualization_exercise.html#load-data",
    "href": "visualization_exercise.html#load-data",
    "title": "Visualization Exercise",
    "section": "Load data",
    "text": "Load data\n\nhere()\n\n[1] \"/Users/leahlariscy/Desktop/MADA2023/leahlariscy-MADA-portfolio\"\n\ndonation <- read_csv(\"data/sports-political-donations/sports-political-donations.csv\")\n\nRows: 2798 Columns: 7\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (6): Owner, Team, League, Recipient, Amount, Party\ndbl (1): Election Year\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\ndonation\n\n# A tibble: 2,798 × 7\n   Owner       Team         League Recipient                Amount Elect…¹ Party\n   <chr>       <chr>        <chr>  <chr>                    <chr>    <dbl> <chr>\n 1 Adam Silver Commissioner NBA    WRIGHT 2016              $4,000    2016 Demo…\n 2 Adam Silver Commissioner NBA    BIDEN FOR PRESIDENT      $2,800    2020 Demo…\n 3 Adam Silver Commissioner NBA    CORY 2020                $2,700    2020 Demo…\n 4 Adam Silver Commissioner NBA    Kamala Harris for the P… $2,700    2020 Demo…\n 5 Adam Silver Commissioner NBA    Win The Era PAC          $2,700    2020 Demo…\n 6 Adam Silver Commissioner NBA    KOHL FOR CONGRESS        $2,000    2018 Demo…\n 7 Adam Silver Commissioner NBA    BETO FOR TEXAS           $1,000    2018 Demo…\n 8 Adam Silver Commissioner NBA    MONTANANS FOR TESTER     $1,000    2018 Demo…\n 9 Adam Silver Commissioner NBA    SERVE AMERICA PAC        $1,000    2018 Demo…\n10 Adam Silver Commissioner NBA    ADAM SCHLEIFER FOR CONG… $1,000    2020 Demo…\n# … with 2,788 more rows, and abbreviated variable name ¹​`Election Year`\n# ℹ Use `print(n = ...)` to see more rows"
  },
  {
    "objectID": "visualization_exercise.html#clean-and-wrangle-data",
    "href": "visualization_exercise.html#clean-and-wrangle-data",
    "title": "Visualization Exercise",
    "section": "Clean and wrangle data",
    "text": "Clean and wrangle data\n\ndonation_clean <- donation %>% \n  filter(League ==c(\"MLB\",\"NASCAR\",\"NBA\",\"NFL\",\"NHL\",\"WNBA\")) %>%\n  filter(Party ==c(\"Democrat\",\"Republican\")) %>% \n  mutate(Amount = parse_number(Amount)) %>% \n  group_by(League,`Election Year`,Party) %>% \n  summarise(party_donations = sum(Amount)) %>% \n  ungroup() \n\nWarning in League == c(\"MLB\", \"NASCAR\", \"NBA\", \"NFL\", \"NHL\", \"WNBA\"): longer\nobject length is not a multiple of shorter object length\n\n\nWarning in Party == c(\"Democrat\", \"Republican\"): longer object length is not a\nmultiple of shorter object length\n\n\n`summarise()` has grouped output by 'League', 'Election Year'. You can override\nusing the `.groups` argument."
  },
  {
    "objectID": "visualization_exercise.html#plot-data",
    "href": "visualization_exercise.html#plot-data",
    "title": "Visualization Exercise",
    "section": "Plot data",
    "text": "Plot data\n\ndonation_plot <- donation_clean %>%\nggplot(aes(fill=Party, y=party_donations, x=`Election Year`)) +\ngeom_bar(position = \"fill\", stat = \"identity\", color = \"white\") +\nfacet_wrap(as.factor(donation_clean$League)) + #plot by League\nscale_fill_manual(name=\"DONATIONS TO\", values=c(\"#00A5E3\", \"#CC0000\"), #looked up hexcodes on google\nlabels=c(\"DEMOCRATS\",\"REPUBLICANS\")) + #fill colors in correct order\ntheme_fivethirtyeight() +\nscale_x_continuous(breaks = seq(2016,2020,2)) + #2 year breaks between 2016 & 2020\nlabs(title = \"Across leagues, majority of donations go to Republicans\",\nsubtitle = \"Share of donations from team owners in six leagues, per year, league and party\") +\ntheme(legend.title = element_text(face = \"bold\", size = 16),\nlegend.text = element_text(size = 16),\nplot.title.position = \"plot\",\nplot.title = element_text(face = \"bold\", size = 24),\nplot.subtitle = element_text(size = 18),\nlegend.position = \"top\",\naxis.text.x = element_text(size = 14))\ndonation_plot\n\n\n\n\nBecause I had to remove some data, my plot looks slightly different but still similar."
  },
  {
    "objectID": "tidytuesday_exercise.html#loading-packages-and-set-figure-size",
    "href": "tidytuesday_exercise.html#loading-packages-and-set-figure-size",
    "title": "Tidy Tuesday Exercise",
    "section": "Loading packages and set figure size",
    "text": "Loading packages and set figure size\n\nlibrary(tidyverse)\n\n── Attaching packages ─────────────────────────────────────── tidyverse 1.3.2 ──\n✔ ggplot2 3.4.0     ✔ purrr   1.0.1\n✔ tibble  3.1.8     ✔ dplyr   1.0.9\n✔ tidyr   1.2.0     ✔ stringr 1.4.1\n✔ readr   2.1.2     ✔ forcats 0.5.2\n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\n\nlibrary(plotly)\n\n\nAttaching package: 'plotly'\n\nThe following object is masked from 'package:ggplot2':\n\n    last_plot\n\nThe following object is masked from 'package:stats':\n\n    filter\n\nThe following object is masked from 'package:graphics':\n\n    layout\n\nlibrary(skimr)\nlibrary(ggpmisc)\n\nLoading required package: ggpp\n\nAttaching package: 'ggpp'\n\nThe following object is masked from 'package:ggplot2':\n\n    annotate\n\nknitr::opts_chunk$set(fig.width=10, fig.height=8)"
  },
  {
    "objectID": "tidytuesday_exercise.html#data-loading",
    "href": "tidytuesday_exercise.html#data-loading",
    "title": "Tidy Tuesday Exercise",
    "section": "Data loading",
    "text": "Data loading\nFollow the TidyTuesday instructions for 2023-02-14\n\nage_gaps <- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2023/2023-02-14/age_gaps.csv')\n\nRows: 1155 Columns: 13\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (6): movie_name, director, actor_1_name, actor_2_name, character_1_gend...\ndbl  (5): release_year, age_difference, couple_number, actor_1_age, actor_2_age\ndate (2): actor_1_birthdate, actor_2_birthdate\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message."
  },
  {
    "objectID": "tidytuesday_exercise.html#data-exploration",
    "href": "tidytuesday_exercise.html#data-exploration",
    "title": "Tidy Tuesday Exercise",
    "section": "Data exploration",
    "text": "Data exploration\n\nskim(age_gaps)\n\n\nData summary\n\n\nName\nage_gaps\n\n\nNumber of rows\n1155\n\n\nNumber of columns\n13\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\ncharacter\n6\n\n\nDate\n2\n\n\nnumeric\n5\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: character\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nempty\nn_unique\nwhitespace\n\n\n\n\nmovie_name\n0\n1\n2\n43\n0\n830\n0\n\n\ndirector\n0\n1\n3\n31\n0\n510\n0\n\n\nactor_1_name\n0\n1\n6\n22\n0\n567\n0\n\n\nactor_2_name\n0\n1\n7\n27\n0\n647\n0\n\n\ncharacter_1_gender\n0\n1\n3\n5\n0\n2\n0\n\n\ncharacter_2_gender\n0\n1\n3\n5\n0\n2\n0\n\n\n\nVariable type: Date\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nmedian\nn_unique\n\n\n\n\nactor_1_birthdate\n0\n1\n1889-04-16\n1996-06-01\n1964-10-03\n562\n\n\nactor_2_birthdate\n0\n1\n1906-10-06\n1996-11-11\n1974-07-30\n640\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\nrelease_year\n0\n1\n2000.80\n16.37\n1935\n1997\n2004\n2012\n2022\n▁▁▁▆▇\n\n\nage_difference\n0\n1\n10.42\n8.51\n0\n4\n8\n15\n52\n▇▃▂▁▁\n\n\ncouple_number\n0\n1\n1.40\n0.75\n1\n1\n1\n2\n7\n▇▁▁▁▁\n\n\nactor_1_age\n0\n1\n40.64\n10.42\n18\n33\n39\n47\n81\n▂▇▅▂▁\n\n\nactor_2_age\n0\n1\n30.21\n7.50\n17\n25\n29\n34\n68\n▇▇▂▁▁\n\n\n\n\n\nBy using skim(), I can see many interesting things about the data:\n\nThe mean age difference between couples is about 10 years.\nThere are 830 unique movies listed, spanning from 1935 to 2022, with most movies only having one couple each.\nSome actor names are repeated upwards of 20 times, showing that they have been involved in multiple couples."
  },
  {
    "objectID": "tidytuesday_exercise.html#ideas-for-analysis",
    "href": "tidytuesday_exercise.html#ideas-for-analysis",
    "title": "Tidy Tuesday Exercise",
    "section": "Ideas for analysis",
    "text": "Ideas for analysis\n\nI will start by designating sexuality of each couple into three groups (straight, gay, sapphic) because I am interested to see how many queer couples there are. If there are enough, we could look at age gap differences between each group.\nI will then determine which gender is the oldest in each pair because I hypothesize that men will be older more of the time.\nI will start with these two questions for now and see where they take me"
  },
  {
    "objectID": "tidytuesday_exercise.html#mutate-data",
    "href": "tidytuesday_exercise.html#mutate-data",
    "title": "Tidy Tuesday Exercise",
    "section": "Mutate data",
    "text": "Mutate data\n\nClassifying sexuality of each couple\nHere I will create a new variable called sexuality based on whether each couple is of same or opposite gender, creating three labels for these relationships: straight (man & woman), gay (man & man), and sapphic (woman & woman)\nI will also look at how many observations there are for each sexuality.\n\nage_gaps_sexuality <- age_gaps %>% \n  mutate(sexuality = case_when(character_1_gender == 'man' & character_2_gender == 'woman' ~ 'straight',\n                               character_1_gender == 'man' & character_2_gender == 'man' ~ 'gay',\n                               character_1_gender == 'woman' & character_2_gender == 'woman' ~ 'sapphic',\n                               character_2_gender == 'man' & character_1_gender == 'woman' ~ 'straight',\n                               character_2_gender == 'man' & character_1_gender == 'man' ~ 'gay',\n                               character_2_gender == 'woman' & character_1_gender == 'woman' ~ 'sapphic'))\nsexuality_count <- age_gaps_sexuality %>% count(sexuality)\nsexuality_count <- sexuality_count %>% mutate(proportion = n/sum(n))\ntibble(sexuality_count)\n\n# A tibble: 3 × 3\n  sexuality     n proportion\n  <chr>     <int>      <dbl>\n1 gay          12    0.0104 \n2 sapphic      11    0.00952\n3 straight   1132    0.980  \n\n\nHere, you see that 98% of couples in this data set can be defined as heterosexual.\n\n\nCounting how many times each gender is older than their partner\nHere, I will count the number of times each gender is older and then calculate that proportion.\n\nolder_count <- age_gaps %>% count(character_1_gender)\nolder_count <- older_count %>% mutate(proportion = n/sum(n))\ntibble(older_count)\n\n# A tibble: 2 × 3\n  character_1_gender     n proportion\n  <chr>              <int>      <dbl>\n1 man                  941      0.815\n2 woman                214      0.185\n\n\nAs you can see here, men in Hollywood are much more likely to be older than their partner than women are. In this data set, men were older than their partner 80% of the time."
  },
  {
    "objectID": "tidytuesday_exercise.html#data-visualization",
    "href": "tidytuesday_exercise.html#data-visualization",
    "title": "Tidy Tuesday Exercise",
    "section": "Data visualization",
    "text": "Data visualization\n\nDifference in average age gaps between straight, gay, and sapphic couples\n\nage_gaps_sexuality %>% ggplot(aes(sexuality, age_difference, color = sexuality)) +\n  geom_boxplot() +\n  ggthemes::theme_fivethirtyeight()\n\n\n\n\nIt appears that gay couples have a higher average age gap than other sexualities, but remember that they make up less than 1% of observations\n\n\nProportion of sexualities in couples throughout the years\n\nage_gaps_sexuality %>% ggplot(aes(y = couple_number, x = release_year, fill = sexuality)) + \n  geom_bar(stat = \"identity\") +\n  scale_x_continuous(name = \"Year Released\", breaks = seq(1930,2022,10)) +\n  ggthemes::theme_fivethirtyeight()\n\n\n\n\nOnly straight couples were documented in Hollywood prior to the 1990s. Queer couplings began to be documented in the 1990s and early 2000s, but still make up a small portion of couples which we saw earlier. We can also note that queer couplings started to pop up around the time that couple numbers in Hollywood dramatically increased in the late 1990s.\n\n\nDifference in age gaps between older men and women\n\nage_gaps %>% ggplot(aes(character_1_gender, age_difference, color = character_1_gender)) +\n  geom_boxplot() +\n  scale_color_manual(values = c('#00C4D4', '#634490')) +\n   ggthemes::theme_fivethirtyeight()\n\n\n\n\nWithin Hollywood, older men tend to have a higher age gap with their partner than older women do.\n\n\nDifference in age gaps between younger men and women\n\nage_gaps %>% ggplot(aes(character_2_gender, age_difference, color = character_2_gender)) +\n  geom_boxplot() +\n  scale_color_manual(values = c('#00C4D4', '#634490')) +\n   ggthemes::theme_fivethirtyeight()\n\n\n\n\nWithin Hollywood, younger men tend to have a smaller age gap with their partners compared to younger women who have a larger average age gap.\n\n\nLinear regression of age vs age gap between men and women\n\nage_gaps %>% ggplot(aes(actor_1_age, age_difference, color = character_1_gender)) +\n  stat_poly_line() +\n  stat_poly_eq() +\n  geom_jitter() +\n  scale_color_manual(name = \"Gender\", values = c('#00C4D4', '#634490')) +\n  ggthemes::theme_fivethirtyeight() +\n  labs(title = \"Linear model of older partner's age vs. relationship age gap\")\n\n\n\n\nMen in Hollywood who are older are more likely to have an increased age gap in their relationships as they age.\n\nage_gaps %>% ggplot(aes(actor_2_age, age_difference, color = character_2_gender)) +\n  stat_poly_line() +\n  stat_poly_eq() +\n  geom_jitter() +\n  scale_color_manual(values = c('#00C4D4', '#634490')) +\n  ggthemes::theme_fivethirtyeight() +\n  labs(title = \"Linear model of younger parter's age vs. relationship age gap\")\n\n\n\n\nWe do not see this same trend with the younger partners. There are less men who are younger than their partner, and there seems to be no indication that their age is a determining factor in their relationship age gap.\nThere are far more women who are younger than their partner, and overall it appears there are less women in couples past the age of 40, compared to the first scatter plot where men are in couples well past their 40s."
  },
  {
    "objectID": "tidytuesday_exercise.html#discussion-and-conclusions",
    "href": "tidytuesday_exercise.html#discussion-and-conclusions",
    "title": "Tidy Tuesday Exercise",
    "section": "Discussion and conclusions",
    "text": "Discussion and conclusions\nWhat I learned from looking at this data of Hollywood couples on the same movie set:\n\n98% of documented couples were heterosexual\nMen were more likely to date someone younger than them then women were\nOlder men had a higher average age gap in their relationships, meaning they were more likely to date women much younger than them than older women were to date much younger men\nOlder partners of both genders showed an increase in relationship age gaps as their own age increased, although this was much more pronounced for men, meaning that as these men age, they continue to date young women\n\nFrom this data exploration, I have concluded that on average, men in Hollywood tend to date much younger women than themselves. They also continue to date much younger women as they age. I would also be interested in looking at the average age of all men recorded vs the average age of women because I have a feeling that men on average are older.\nTo conclude, and to quote Taylor Swift, “I’ll get older, but your lovers stay my age”."
  },
  {
    "objectID": "fluanalysis/code/fitting.html",
    "href": "fluanalysis/code/fitting.html",
    "title": "Flu Data Model Fitting",
    "section": "",
    "text": "library(tidymodels)\n\n── Attaching packages ────────────────────────────────────── tidymodels 1.0.0 ──\n\n\n✔ broom        1.0.3     ✔ recipes      1.0.5\n✔ dials        1.1.0     ✔ rsample      1.1.1\n✔ dplyr        1.1.0     ✔ tibble       3.1.8\n✔ ggplot2      3.4.1     ✔ tidyr        1.3.0\n✔ infer        1.0.4     ✔ tune         1.0.1\n✔ modeldata    1.1.0     ✔ workflows    1.1.3\n✔ parsnip      1.0.4     ✔ workflowsets 1.0.0\n✔ purrr        1.0.1     ✔ yardstick    1.1.0\n\n\n── Conflicts ───────────────────────────────────────── tidymodels_conflicts() ──\n✖ purrr::discard() masks scales::discard()\n✖ dplyr::filter()  masks stats::filter()\n✖ dplyr::lag()     masks stats::lag()\n✖ recipes::step()  masks stats::step()\n• Search for functions across packages at https://www.tidymodels.org/find/\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ forcats   1.0.0     ✔ readr     2.1.4\n✔ lubridate 1.9.2     ✔ stringr   1.5.0\n\n\n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ readr::col_factor() masks scales::col_factor()\n✖ purrr::discard()    masks scales::discard()\n✖ dplyr::filter()     masks stats::filter()\n✖ stringr::fixed()    masks recipes::fixed()\n✖ dplyr::lag()        masks stats::lag()\n✖ readr::spec()       masks yardstick::spec()\nℹ Use the \u001b]8;;http://conflicted.r-lib.org/\u0007conflicted package\u001b]8;;\u0007 to force all conflicts to become errors\n\nlibrary(here)\n\nhere() starts at /Users/leahlariscy/Desktop/MADA2023/leahlariscy-MADA-portfolio\n\nlibrary(dotwhisker)\n\n\n\n\n\nsymptoms_fit <- readRDS(here(\"fluanalysis/data/processed_data/symptoms_clean.RDS\"))\ntibble(symptoms_fit) #quick look at data\n\n# A tibble: 730 × 32\n   SwollenLymph…¹ Chest…² Chill…³ Nasal…⁴ CoughYN Sneeze Fatigue Subje…⁵ Heada…⁶\n   <fct>          <fct>   <fct>   <fct>   <fct>   <fct>  <fct>   <fct>   <fct>  \n 1 Yes            No      No      No      Yes     No     Yes     Yes     Yes    \n 2 Yes            Yes     No      Yes     Yes     No     Yes     Yes     Yes    \n 3 Yes            Yes     Yes     Yes     No      Yes    Yes     Yes     Yes    \n 4 Yes            Yes     Yes     Yes     Yes     Yes    Yes     Yes     Yes    \n 5 Yes            No      Yes     No      No      No     Yes     Yes     Yes    \n 6 No             No      Yes     No      Yes     Yes    Yes     Yes     Yes    \n 7 No             No      Yes     No      Yes     No     Yes     Yes     No     \n 8 No             Yes     Yes     Yes     Yes     Yes    Yes     Yes     Yes    \n 9 Yes            Yes     Yes     Yes     Yes     No     Yes     Yes     Yes    \n10 No             Yes     No      Yes     Yes     No     Yes     No      Yes    \n# … with 720 more rows, 23 more variables: Weakness <fct>, WeaknessYN <fct>,\n#   CoughIntensity <fct>, CoughYN2 <fct>, Myalgia <fct>, MyalgiaYN <fct>,\n#   RunnyNose <fct>, AbPain <fct>, ChestPain <fct>, Diarrhea <fct>,\n#   EyePn <fct>, Insomnia <fct>, ItchyEye <fct>, Nausea <fct>, EarPn <fct>,\n#   Hearing <fct>, Pharyngitis <fct>, Breathless <fct>, ToothPn <fct>,\n#   Vision <fct>, Vomit <fct>, Wheeze <fct>, BodyTemp <dbl>, and abbreviated\n#   variable names ¹​SwollenLymphNodes, ²​ChestCongestion, ³​ChillsSweats, …\n\n\nData looks good to go\n\n\n\n\n\n\ndata_split <- initial_split(symptoms_fit, prop = 3/4)\n\ntrain_data <- training(data_split)\ntest_data <- testing(data_split)\n\n\n\n\n\nlm_mod <- linear_reg() #set model type as linear regression\n\n\n\n\n\nrecipe_bodytemp <- recipe(BodyTemp ~ ., data = train_data)\n\n\n\n\n\nbodytemp_lm_workflow <- workflow() %>% \n  add_model(lm_mod) %>% \n  add_recipe(recipe_bodytemp)\n\n\n\n\n\nbodytemp_fit <- bodytemp_lm_workflow %>% \n  fit(data = train_data)\ntidy(bodytemp_fit)\n\n# A tibble: 38 × 5\n   term                 estimate std.error statistic p.value\n   <chr>                   <dbl>     <dbl>     <dbl>   <dbl>\n 1 (Intercept)           97.7        0.363   269.    0      \n 2 SwollenLymphNodesYes  -0.172      0.107    -1.60  0.110  \n 3 ChestCongestionYes     0.130      0.112     1.17  0.244  \n 4 ChillsSweatsYes        0.255      0.148     1.72  0.0862 \n 5 NasalCongestionYes    -0.242      0.130    -1.87  0.0622 \n 6 CoughYNYes             0.271      0.276     0.982 0.327  \n 7 SneezeYes             -0.335      0.115    -2.93  0.00356\n 8 FatigueYes             0.264      0.181     1.46  0.145  \n 9 SubjectiveFeverYes     0.339      0.119     2.85  0.00451\n10 HeadacheYes            0.0866     0.142     0.608 0.543  \n# … with 28 more rows\n\n\n\n\n\n\ntidy(bodytemp_fit) %>% \n  dwplot(dot_args = list(size = 2, color = \"black\"),\n         whisker_args = list(color = \"black\"),\n         vline = geom_vline(xintercept = 0, \n                            colour = \"grey50\", linetype = 2))\n\n\n\n\n\n\n\n\nbodytemp_aug_test <- augment(bodytemp_fit, test_data)\n\nWarning in predict.lm(object = object$fit, newdata = new_data, type =\n\"response\"): prediction from a rank-deficient fit may be misleading\n\nbodytemp_aug_test %>% select(BodyTemp, .pred)\n\n# A tibble: 183 × 2\n   BodyTemp .pred\n      <dbl> <dbl>\n 1    100.   99.3\n 2     98.5  98.6\n 3     97.8  98.7\n 4     98.1  98.4\n 5    100.   99.1\n 6     98.7  98.3\n 7     98.8  99.2\n 8    101.   99.0\n 9     98.3  98.4\n10     99.3  98.9\n# … with 173 more rows\n\n\n\n\n\n\nbodytemp_aug_test %>% \n  rmse(truth = BodyTemp, .pred)\n\n# A tibble: 1 × 3\n  .metric .estimator .estimate\n  <chr>   <chr>          <dbl>\n1 rmse    standard        1.18\n\n\nI think this means that this model is estimating body temp incorrectly by this amount (in either direction)\n\n\n\n\n\n\nSince we already defined the training set and testing set, we don’t need to do that again. We will just reuse those. We also already defined the model, so we don’t need to do that again.\n\nrecipe_bodytemp2 <- recipe(BodyTemp ~ RunnyNose, data = train_data)\n\nHere, we have set the outcome of interest to be body temperature, and predictor of interest to be runny nose.\n\n\n\n\nbodytemp_lm_workflow2 <- workflow() %>% \n  add_model(lm_mod) %>% \n  add_recipe(recipe_bodytemp2)\n\n\n\n\n\nbodytemp_fit2 <- bodytemp_lm_workflow2 %>% \n  fit(data = train_data)\ntidy(bodytemp_fit2)\n\n# A tibble: 2 × 5\n  term         estimate std.error statistic p.value\n  <chr>           <dbl>     <dbl>     <dbl>   <dbl>\n1 (Intercept)    99.1      0.0919   1078.    0     \n2 RunnyNoseYes   -0.235    0.110      -2.13  0.0333\n\n\nNow we have trained the model using the training data set.\n\n\n\n\ntidy(bodytemp_fit2) %>% \n  dwplot(dot_args = list(size = 2, color = \"black\"),\n         whisker_args = list(color = \"black\"),\n         vline = geom_vline(xintercept = 0, \n                            colour = \"grey50\", linetype = 2))\n\n\n\n\nLooks like runny nose is a negative predictor of body temp (body temp is more likely to be lower if runny nose symptom is present)\n\n\n\n\nbodytemp_aug_test2 <- augment(bodytemp_fit2, test_data)\nbodytemp_aug_test2 %>% select(BodyTemp, .pred)\n\n# A tibble: 183 × 2\n   BodyTemp .pred\n      <dbl> <dbl>\n 1    100.   99.1\n 2     98.5  98.8\n 3     97.8  98.8\n 4     98.1  98.8\n 5    100.   98.8\n 6     98.7  98.8\n 7     98.8  99.1\n 8    101.   98.8\n 9     98.3  99.1\n10     99.3  98.8\n# … with 173 more rows\n\n\n\n\n\n\nbodytemp_aug_test2 %>% \n  rmse(truth = BodyTemp, .pred)\n\n# A tibble: 1 × 3\n  .metric .estimator .estimate\n  <chr>   <chr>          <dbl>\n1 rmse    standard        1.22\n\n\nThis is a similar output to what we saw in the first model, where estimation of body temp is slightly off by about 1 degree.\n\n\n\n\n\n\nWe will continue to use the model testing and training data sets that we created at the start. However, since we now want to create a logistic regression (outcome of interest is categorical), we will need to define a new model\n\nlog_mod <- logistic_reg() %>% \n  set_engine(\"glm\")\n\n\n\n\n\nrecipe_nausea <- recipe(Nausea ~., data = train_data)\n\nThis sets the stage to predict nausea outcomes based on all other variables in the data set (predictors)\n\n\n\n\nnausea_log_wf <- workflow() %>% \n  add_model(log_mod) %>% \n  add_recipe(recipe_nausea)\n\n\n\n\n\nnausea_fit <- nausea_log_wf %>% \n  fit(data = train_data)\n\nnausea_fit %>% extract_fit_parsnip() %>% \n  tidy()\n\n# A tibble: 38 × 5\n   term                 estimate std.error statistic p.value\n   <chr>                   <dbl>     <dbl>     <dbl>   <dbl>\n 1 (Intercept)            -8.33      9.26     -0.899  0.369 \n 2 SwollenLymphNodesYes   -0.337     0.231    -1.46   0.143 \n 3 ChestCongestionYes      0.222     0.243     0.916  0.360 \n 4 ChillsSweatsYes         0.285     0.338     0.841  0.400 \n 5 NasalCongestionYes      0.648     0.290     2.23   0.0255\n 6 CoughYNYes             -0.388     0.603    -0.644  0.520 \n 7 SneezeYes               0.126     0.247     0.509  0.611 \n 8 FatigueYes              0.308     0.424     0.727  0.467 \n 9 SubjectiveFeverYes      0.253     0.263     0.961  0.337 \n10 HeadacheYes             0.314     0.320     0.978  0.328 \n# … with 28 more rows\n\n\nNow we have trained the model, so let’s use the test data to see how well this model predicts nausea.\n\n\n\n\npredict(nausea_fit, test_data)\n\nWarning in predict.lm(object, newdata, se.fit, scale = 1, type = if (type == :\nprediction from a rank-deficient fit may be misleading\n\n\n# A tibble: 183 × 1\n   .pred_class\n   <fct>      \n 1 No         \n 2 No         \n 3 No         \n 4 No         \n 5 No         \n 6 No         \n 7 No         \n 8 No         \n 9 No         \n10 No         \n# … with 173 more rows\n\n\n\n\n\n\nnausea_aug_test <- augment(nausea_fit, test_data)\n\nWarning in predict.lm(object, newdata, se.fit, scale = 1, type = if (type == :\nprediction from a rank-deficient fit may be misleading\n\nWarning in predict.lm(object, newdata, se.fit, scale = 1, type = if (type == :\nprediction from a rank-deficient fit may be misleading\n\nnausea_aug_test %>% \n  roc_curve(truth = Nausea, .pred_Yes, event_level = \"second\") %>% \n  autoplot()\n\nWarning: Returning more (or less) than 1 row per `summarise()` group was deprecated in\ndplyr 1.1.0.\nℹ Please use `reframe()` instead.\nℹ When switching from `summarise()` to `reframe()`, remember that `reframe()`\n  always returns an ungrouped data frame and adjust accordingly.\nℹ The deprecated feature was likely used in the yardstick package.\n  Please report the issue at <\u001b]8;;https://github.com/tidymodels/yardstick/issues\u0007https://github.com/tidymodels/yardstick/issues\u001b]8;;\u0007>.\n\n\n\n\nnausea_aug_test %>% roc_auc(truth = Nausea, .pred_Yes, \n                            event_level = \"second\")\n\n# A tibble: 1 × 3\n  .metric .estimator .estimate\n  <chr>   <chr>          <dbl>\n1 roc_auc binary         0.714\n\n\nI think what this shows is that the model is a pretty decent predictor of nausea, however, it is more sensitive than it is specific, meaning that it is good at indicating true positives but not as good at indicating true negatives.\n\n\n\n\n\n\nSince we have already split the data and defined the appropriate model, we will just need to create a new recipe that predicts nausea based on runny nose.\n\nrecipe_nausea2 <- recipe(Nausea ~ RunnyNose, data = train_data)\n\n\n\n\n\nnausea_log_wf2 <- workflow() %>% \n  add_model(log_mod) %>% \n  add_recipe(recipe_nausea2)\n\n\n\n\n\nnausea_fit2 <- nausea_log_wf2 %>% \n  fit(data = train_data)\n\nnausea_fit2 %>% extract_fit_parsnip() %>% \n  tidy()\n\n# A tibble: 2 × 5\n  term         estimate std.error statistic   p.value\n  <chr>           <dbl>     <dbl>     <dbl>     <dbl>\n1 (Intercept)    -0.693     0.165    -4.20  0.0000270\n2 RunnyNoseYes    0.157     0.196     0.801 0.423    \n\n\n\n\n\n\npredict(nausea_fit2, test_data)\n\n# A tibble: 183 × 1\n   .pred_class\n   <fct>      \n 1 No         \n 2 No         \n 3 No         \n 4 No         \n 5 No         \n 6 No         \n 7 No         \n 8 No         \n 9 No         \n10 No         \n# … with 173 more rows\n\n\n\n\n\n\nnausea_aug_test2 <- augment(nausea_fit2, test_data)\n\nnausea_aug_test2 %>% \n  roc_curve(truth = Nausea, .pred_Yes, event_level = \"second\") %>% \n  autoplot()\n\n\n\nnausea_aug_test2 %>% roc_auc(truth = Nausea, .pred_Yes, \n                            event_level = \"second\")\n\n# A tibble: 1 × 3\n  .metric .estimator .estimate\n  <chr>   <chr>          <dbl>\n1 roc_auc binary         0.473"
  },
  {
    "objectID": "fluanalysis/code/exploration.html",
    "href": "fluanalysis/code/exploration.html",
    "title": "Flu Data Exploration",
    "section": "",
    "text": "library(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.0     ✔ readr     2.1.4\n✔ forcats   1.0.0     ✔ stringr   1.5.0\n✔ ggplot2   3.4.1     ✔ tibble    3.1.8\n✔ lubridate 1.9.2     ✔ tidyr     1.3.0\n✔ purrr     1.0.1     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the \u001b]8;;http://conflicted.r-lib.org/\u0007conflicted package\u001b]8;;\u0007 to force all conflicts to become errors\n\nlibrary(here)\n\nhere() starts at /Users/leahlariscy/Desktop/MADA2023/leahlariscy-MADA-portfolio\n\n\n\n\n\n\nsymptoms_clean <- readRDS(here(\"fluanalysis/data/processed_data/symptoms_clean.RDS\"))\n\n\n\n\n\nskimr::skim(symptoms_clean)\n\n\nData summary\n\n\nName\nsymptoms_clean\n\n\nNumber of rows\n730\n\n\nNumber of columns\n32\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\nfactor\n31\n\n\nnumeric\n1\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: factor\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nordered\nn_unique\ntop_counts\n\n\n\n\nSwollenLymphNodes\n0\n1\nFALSE\n2\nNo: 418, Yes: 312\n\n\nChestCongestion\n0\n1\nFALSE\n2\nYes: 407, No: 323\n\n\nChillsSweats\n0\n1\nFALSE\n2\nYes: 600, No: 130\n\n\nNasalCongestion\n0\n1\nFALSE\n2\nYes: 563, No: 167\n\n\nCoughYN\n0\n1\nFALSE\n2\nYes: 655, No: 75\n\n\nSneeze\n0\n1\nFALSE\n2\nYes: 391, No: 339\n\n\nFatigue\n0\n1\nFALSE\n2\nYes: 666, No: 64\n\n\nSubjectiveFever\n0\n1\nFALSE\n2\nYes: 500, No: 230\n\n\nHeadache\n0\n1\nFALSE\n2\nYes: 615, No: 115\n\n\nWeakness\n0\n1\nFALSE\n4\nMod: 338, Mil: 223, Sev: 120, Non: 49\n\n\nWeaknessYN\n0\n1\nFALSE\n2\nYes: 681, No: 49\n\n\nCoughIntensity\n0\n1\nFALSE\n4\nMod: 357, Sev: 172, Mil: 154, Non: 47\n\n\nCoughYN2\n0\n1\nFALSE\n2\nYes: 683, No: 47\n\n\nMyalgia\n0\n1\nFALSE\n4\nMod: 325, Mil: 213, Sev: 113, Non: 79\n\n\nMyalgiaYN\n0\n1\nFALSE\n2\nYes: 651, No: 79\n\n\nRunnyNose\n0\n1\nFALSE\n2\nYes: 519, No: 211\n\n\nAbPain\n0\n1\nFALSE\n2\nNo: 639, Yes: 91\n\n\nChestPain\n0\n1\nFALSE\n2\nNo: 497, Yes: 233\n\n\nDiarrhea\n0\n1\nFALSE\n2\nNo: 631, Yes: 99\n\n\nEyePn\n0\n1\nFALSE\n2\nNo: 617, Yes: 113\n\n\nInsomnia\n0\n1\nFALSE\n2\nYes: 415, No: 315\n\n\nItchyEye\n0\n1\nFALSE\n2\nNo: 551, Yes: 179\n\n\nNausea\n0\n1\nFALSE\n2\nNo: 475, Yes: 255\n\n\nEarPn\n0\n1\nFALSE\n2\nNo: 568, Yes: 162\n\n\nHearing\n0\n1\nFALSE\n2\nNo: 700, Yes: 30\n\n\nPharyngitis\n0\n1\nFALSE\n2\nYes: 611, No: 119\n\n\nBreathless\n0\n1\nFALSE\n2\nNo: 436, Yes: 294\n\n\nToothPn\n0\n1\nFALSE\n2\nNo: 565, Yes: 165\n\n\nVision\n0\n1\nFALSE\n2\nNo: 711, Yes: 19\n\n\nVomit\n0\n1\nFALSE\n2\nNo: 652, Yes: 78\n\n\nWheeze\n0\n1\nFALSE\n2\nNo: 510, Yes: 220\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\nBodyTemp\n0\n1\n98.94\n1.2\n97.2\n98.2\n98.5\n99.3\n103.1\n▇▇▂▁▁\n\n\n\n\n\nLooks like the data did load properly. There are 730 observations of 32 variables with no NAs. There are 31 factor and 1 integer variables.\n\n\n\nOutcomes of interest: body temperature, nausea\nPredictors of interest: weakness, fatigue, headache\n\n\n\n\nsummary(symptoms_clean)\n\n SwollenLymphNodes ChestCongestion ChillsSweats NasalCongestion CoughYN  \n No :418           No :323         No :130      No :167         No : 75  \n Yes:312           Yes:407         Yes:600      Yes:563         Yes:655  \n                                                                         \n                                                                         \n                                                                         \n                                                                         \n Sneeze    Fatigue   SubjectiveFever Headache      Weakness   WeaknessYN\n No :339   No : 64   No :230         No :115   None    : 49   No : 49   \n Yes:391   Yes:666   Yes:500         Yes:615   Mild    :223   Yes:681   \n                                               Moderate:338             \n                                               Severe  :120             \n                                                                        \n                                                                        \n  CoughIntensity CoughYN2      Myalgia    MyalgiaYN RunnyNose AbPain   \n None    : 47    No : 47   None    : 79   No : 79   No :211   No :639  \n Mild    :154    Yes:683   Mild    :213   Yes:651   Yes:519   Yes: 91  \n Moderate:357              Moderate:325                                \n Severe  :172              Severe  :113                                \n                                                                       \n                                                                       \n ChestPain Diarrhea  EyePn     Insomnia  ItchyEye  Nausea    EarPn    \n No :497   No :631   No :617   No :315   No :551   No :475   No :568  \n Yes:233   Yes: 99   Yes:113   Yes:415   Yes:179   Yes:255   Yes:162  \n                                                                      \n                                                                      \n                                                                      \n                                                                      \n Hearing   Pharyngitis Breathless ToothPn   Vision    Vomit     Wheeze   \n No :700   No :119     No :436    No :565   No :711   No :652   No :510  \n Yes: 30   Yes:611     Yes:294    Yes:165   Yes: 19   Yes: 78   Yes:220  \n                                                                         \n                                                                         \n                                                                         \n                                                                         \n    BodyTemp     \n Min.   : 97.20  \n 1st Qu.: 98.20  \n Median : 98.50  \n Mean   : 98.94  \n 3rd Qu.: 99.30  \n Max.   :103.10  \n\n\nHere we see that most of the categorical variables have either Yes or No responses, simply indicating presence-absence of the symptoms. A few others have a range of responses to address the severity of certain symptoms. There is one continuous variable, BodyTemp, which has a range from 97.2 to 103.1. Nausea, our other outcome of interest, had 475 No and 255 Yes.\n\n\n\n\nsymptoms_clean %>% ggplot(aes(BodyTemp)) +\n  geom_histogram(fill = \"#d65aa8\") +\n  theme_light()\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\nHere we see the distribution of BodyTemp, showing that the most commonly reported body temperature was slightly higher than 98. This checks out, as we saw in the summary report above than the median is 98.5.\n\n\n\n\nsymptoms_clean %>% ggplot(aes(WeaknessYN, BodyTemp, color = WeaknessYN)) +\n  geom_boxplot() +\n  theme_light()\n\n\n\n\nFrom first glance, it appears as if mean body temp increases when weakness is present.\n\n\n\n\nsymptoms_clean %>% ggplot(aes(Fatigue, BodyTemp, color = Fatigue)) +\n  geom_boxplot() +\n  theme_light()\n\n\n\n\nIt appears that mean body temp does increase slightly when fatigue is present.\n\n\n\n\nsymptoms_clean %>% ggplot(aes(Headache, BodyTemp, color = Headache)) +\n  geom_boxplot() +\n  theme_light()\n\n\n\n\nIt appears that mean body temp does increase slightly when headache is present.\n\n\n\n\nsymptoms_clean %>% ggplot(aes(WeaknessYN, Nausea)) +\n  geom_count() +\n  theme_light()\n\n\n\n\nThe most common combination is weakness + no nausea, followed by weakness + nausea. The count size is similar for both though, so there may or may not a significant difference there. The least common observation is lack of weakness but presence of nausea. What this shows is that weakness is more common than no weakness, but that weakness may not necessarily determine nausea.\n\n\n\n\nsymptoms_clean %>% ggplot(aes(Fatigue, Nausea)) +\n  geom_count() +\n  theme_light()\n\n\n\n\nThis output is similar to the one above, where presence of fatigue is most common, but fatigue without the presence of nausea is slightly more common.\n\n\n\n\nsymptoms_clean %>% ggplot(aes(Headache, Nausea)) +\n  geom_count() +\n  theme_light()\n\n\n\n\nLike in the previous two outputs, headaches are more common than not, but lack of nausea with headaches was slightly more common than presence of nausea."
  },
  {
    "objectID": "fluanalysis/code/wrangling.html",
    "href": "fluanalysis/code/wrangling.html",
    "title": "Flu Data Wrangling",
    "section": "",
    "text": "library(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.0     ✔ readr     2.1.4\n✔ forcats   1.0.0     ✔ stringr   1.5.0\n✔ ggplot2   3.4.1     ✔ tibble    3.1.8\n✔ lubridate 1.9.2     ✔ tidyr     1.3.0\n✔ purrr     1.0.1     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the \u001b]8;;http://conflicted.r-lib.org/\u0007conflicted package\u001b]8;;\u0007 to force all conflicts to become errors\n\nlibrary(here)\n\nhere() starts at /Users/leahlariscy/Desktop/MADA2023/leahlariscy-MADA-portfolio\n\n\n\n\n\n\nsymptoms <- readRDS(here(\"fluanalysis/data/raw_data/SympAct_Any_Pos.Rda\"))\n\n\n\n\n\nglimpse(symptoms)\n\nRows: 735\nColumns: 63\n$ DxName1           <fct> \"Influenza like illness - Clinical Dx\", \"Acute tonsi…\n$ DxName2           <fct> NA, \"Influenza like illness - Clinical Dx\", \"Acute p…\n$ DxName3           <fct> NA, NA, NA, NA, NA, NA, NA, NA, \"Fever, unspecified\"…\n$ DxName4           <fct> NA, NA, NA, NA, NA, NA, NA, NA, \"Other fatigue\", NA,…\n$ DxName5           <fct> NA, NA, NA, NA, NA, NA, NA, NA, \"Headache\", NA, NA, …\n$ Unique.Visit      <chr> \"340_17632125\", \"340_17794836\", \"342_17737773\", \"342…\n$ ActivityLevel     <int> 10, 6, 2, 2, 5, 3, 4, 0, 0, 5, 9, 1, 3, 6, 5, 2, 2, …\n$ ActivityLevelF    <fct> 10, 6, 2, 2, 5, 3, 4, 0, 0, 5, 9, 1, 3, 6, 5, 2, 2, …\n$ SwollenLymphNodes <fct> Yes, Yes, Yes, Yes, Yes, No, No, No, Yes, No, Yes, Y…\n$ ChestCongestion   <fct> No, Yes, Yes, Yes, No, No, No, Yes, Yes, Yes, Yes, Y…\n$ ChillsSweats      <fct> No, No, Yes, Yes, Yes, Yes, Yes, Yes, Yes, No, Yes, …\n$ NasalCongestion   <fct> No, Yes, Yes, Yes, No, No, No, Yes, Yes, Yes, Yes, Y…\n$ CoughYN           <fct> Yes, Yes, No, Yes, No, Yes, Yes, Yes, Yes, Yes, No, …\n$ Sneeze            <fct> No, No, Yes, Yes, No, Yes, No, Yes, No, No, No, No, …\n$ Fatigue           <fct> Yes, Yes, Yes, Yes, Yes, Yes, Yes, Yes, Yes, Yes, Ye…\n$ SubjectiveFever   <fct> Yes, Yes, Yes, Yes, Yes, Yes, Yes, Yes, Yes, No, Yes…\n$ Headache          <fct> Yes, Yes, Yes, Yes, Yes, Yes, No, Yes, Yes, Yes, Yes…\n$ Weakness          <fct> Mild, Severe, Severe, Severe, Moderate, Moderate, Mi…\n$ WeaknessYN        <fct> Yes, Yes, Yes, Yes, Yes, Yes, Yes, Yes, Yes, Yes, Ye…\n$ CoughIntensity    <fct> Severe, Severe, Mild, Moderate, None, Moderate, Seve…\n$ CoughYN2          <fct> Yes, Yes, Yes, Yes, No, Yes, Yes, Yes, Yes, Yes, Yes…\n$ Myalgia           <fct> Mild, Severe, Severe, Severe, Mild, Moderate, Mild, …\n$ MyalgiaYN         <fct> Yes, Yes, Yes, Yes, Yes, Yes, Yes, Yes, Yes, Yes, Ye…\n$ RunnyNose         <fct> No, No, Yes, Yes, No, No, Yes, Yes, Yes, Yes, No, No…\n$ AbPain            <fct> No, No, Yes, No, No, No, No, No, No, No, Yes, Yes, N…\n$ ChestPain         <fct> No, No, Yes, No, No, Yes, Yes, No, No, No, No, Yes, …\n$ Diarrhea          <fct> No, No, No, No, No, Yes, No, No, No, No, No, No, No,…\n$ EyePn             <fct> No, No, No, No, Yes, No, No, No, No, No, Yes, No, Ye…\n$ Insomnia          <fct> No, No, Yes, Yes, Yes, No, No, Yes, Yes, Yes, Yes, Y…\n$ ItchyEye          <fct> No, No, No, No, No, No, No, No, No, No, No, No, Yes,…\n$ Nausea            <fct> No, No, Yes, Yes, Yes, Yes, No, No, Yes, Yes, Yes, Y…\n$ EarPn             <fct> No, Yes, No, Yes, No, No, No, No, No, No, No, Yes, Y…\n$ Hearing           <fct> No, Yes, No, No, No, No, No, No, No, No, No, No, No,…\n$ Pharyngitis       <fct> Yes, Yes, Yes, Yes, Yes, Yes, Yes, No, No, No, Yes, …\n$ Breathless        <fct> No, No, Yes, No, No, Yes, No, No, No, Yes, No, Yes, …\n$ ToothPn           <fct> No, No, Yes, No, No, No, No, No, Yes, No, No, Yes, N…\n$ Vision            <fct> No, No, No, No, No, No, No, No, No, No, No, No, No, …\n$ Vomit             <fct> No, No, No, No, No, No, Yes, No, No, No, Yes, Yes, N…\n$ Wheeze            <fct> No, No, No, Yes, No, Yes, No, No, No, No, No, Yes, N…\n$ BodyTemp          <dbl> 98.3, 100.4, 100.8, 98.8, 100.5, 98.4, 102.5, 98.4, …\n$ RapidFluA         <fct> Presumptive Negative For Influenza A, NA, Presumptiv…\n$ RapidFluB         <fct> Presumptive Negative For Influenza B, NA, Presumptiv…\n$ PCRFluA           <fct> NA, NA, NA, NA, NA, NA,  Influenza A Not Detected, N…\n$ PCRFluB           <fct> NA, NA, NA, NA, NA, NA,  Influenza B Not Detected, N…\n$ TransScore1       <dbl> 1, 3, 4, 5, 0, 2, 2, 5, 4, 4, 2, 3, 2, 5, 3, 5, 1, 5…\n$ TransScore1F      <fct> 1, 3, 4, 5, 0, 2, 2, 5, 4, 4, 2, 3, 2, 5, 3, 5, 1, 5…\n$ TransScore2       <dbl> 1, 2, 3, 4, 0, 2, 2, 4, 3, 3, 1, 2, 2, 4, 2, 4, 1, 4…\n$ TransScore2F      <fct> 1, 2, 3, 4, 0, 2, 2, 4, 3, 3, 1, 2, 2, 4, 2, 4, 1, 4…\n$ TransScore3       <dbl> 1, 1, 2, 3, 0, 2, 2, 3, 2, 2, 0, 1, 1, 3, 1, 3, 1, 3…\n$ TransScore3F      <fct> 1, 1, 2, 3, 0, 2, 2, 3, 2, 2, 0, 1, 1, 3, 1, 3, 1, 3…\n$ TransScore4       <dbl> 0, 2, 4, 4, 0, 1, 1, 4, 3, 3, 2, 2, 2, 4, 3, 4, 0, 4…\n$ TransScore4F      <fct> 0, 2, 4, 4, 0, 1, 1, 4, 3, 3, 2, 2, 2, 4, 3, 4, 0, 4…\n$ ImpactScore       <int> 7, 8, 14, 12, 11, 12, 8, 7, 10, 7, 13, 17, 11, 13, 9…\n$ ImpactScore2      <int> 6, 7, 13, 11, 10, 11, 7, 6, 9, 6, 12, 16, 10, 12, 8,…\n$ ImpactScore3      <int> 3, 4, 9, 7, 6, 7, 3, 3, 6, 4, 7, 11, 6, 8, 4, 4, 5, …\n$ ImpactScoreF      <fct> 7, 8, 14, 12, 11, 12, 8, 7, 10, 7, 13, 17, 11, 13, 9…\n$ ImpactScore2F     <fct> 6, 7, 13, 11, 10, 11, 7, 6, 9, 6, 12, 16, 10, 12, 8,…\n$ ImpactScore3F     <fct> 3, 4, 9, 7, 6, 7, 3, 3, 6, 4, 7, 11, 6, 8, 4, 4, 5, …\n$ ImpactScoreFD     <fct> 7, 8, 14, 12, 11, 12, 8, 7, 10, 7, 13, 17, 11, 13, 9…\n$ TotalSymp1        <dbl> 8, 11, 18, 17, 11, 14, 10, 12, 14, 11, 15, 20, 13, 1…\n$ TotalSymp1F       <fct> 8, 11, 18, 17, 11, 14, 10, 12, 14, 11, 15, 20, 13, 1…\n$ TotalSymp2        <dbl> 8, 10, 17, 16, 11, 14, 10, 11, 13, 10, 14, 19, 13, 1…\n$ TotalSymp3        <dbl> 8, 9, 16, 15, 11, 14, 10, 10, 12, 9, 13, 18, 12, 16,…\n\nskimr::skim(symptoms)\n\n\nData summary\n\n\nName\nsymptoms\n\n\nNumber of rows\n735\n\n\nNumber of columns\n63\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\ncharacter\n1\n\n\nfactor\n50\n\n\nnumeric\n12\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: character\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nempty\nn_unique\nwhitespace\n\n\n\n\nUnique.Visit\n0\n1\n10\n12\n0\n735\n0\n\n\n\nVariable type: factor\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nordered\nn_unique\ntop_counts\n\n\n\n\nDxName1\n0\n1.00\nFALSE\n25\nInf: 328, Inf: 131, Fev: 101, Cou: 66\n\n\nDxName2\n280\n0.62\nFALSE\n42\nInf: 126, Inf: 115, Fev: 45, Cou: 41\n\n\nDxName3\n626\n0.15\nFALSE\n37\nInf: 23, Inf: 14, Cou: 10, Fev: 6\n\n\nDxName4\n716\n0.03\nFALSE\n14\nInf: 3, Acu: 2, Enc: 2, Inf: 2\n\n\nDxName5\n734\n0.00\nFALSE\n1\nHea: 1, Acu: 0, Enc: 0, Oth: 0\n\n\nActivityLevelF\n0\n1.00\nFALSE\n11\n3: 125, 5: 97, 4: 95, 2: 80\n\n\nSwollenLymphNodes\n0\n1.00\nFALSE\n2\nNo: 421, Yes: 314\n\n\nChestCongestion\n0\n1.00\nFALSE\n2\nYes: 409, No: 326\n\n\nChillsSweats\n0\n1.00\nFALSE\n2\nYes: 604, No: 131\n\n\nNasalCongestion\n0\n1.00\nFALSE\n2\nYes: 565, No: 170\n\n\nCoughYN\n0\n1.00\nFALSE\n2\nYes: 660, No: 75\n\n\nSneeze\n0\n1.00\nFALSE\n2\nYes: 395, No: 340\n\n\nFatigue\n0\n1.00\nFALSE\n2\nYes: 671, No: 64\n\n\nSubjectiveFever\n0\n1.00\nFALSE\n2\nYes: 505, No: 230\n\n\nHeadache\n0\n1.00\nFALSE\n2\nYes: 620, No: 115\n\n\nWeakness\n0\n1.00\nFALSE\n4\nMod: 341, Mil: 224, Sev: 121, Non: 49\n\n\nWeaknessYN\n0\n1.00\nFALSE\n2\nYes: 686, No: 49\n\n\nCoughIntensity\n0\n1.00\nFALSE\n4\nMod: 360, Sev: 172, Mil: 156, Non: 47\n\n\nCoughYN2\n0\n1.00\nFALSE\n2\nYes: 688, No: 47\n\n\nMyalgia\n0\n1.00\nFALSE\n4\nMod: 327, Mil: 214, Sev: 115, Non: 79\n\n\nMyalgiaYN\n0\n1.00\nFALSE\n2\nYes: 656, No: 79\n\n\nRunnyNose\n0\n1.00\nFALSE\n2\nYes: 524, No: 211\n\n\nAbPain\n0\n1.00\nFALSE\n2\nNo: 642, Yes: 93\n\n\nChestPain\n0\n1.00\nFALSE\n2\nNo: 501, Yes: 234\n\n\nDiarrhea\n0\n1.00\nFALSE\n2\nNo: 636, Yes: 99\n\n\nEyePn\n0\n1.00\nFALSE\n2\nNo: 622, Yes: 113\n\n\nInsomnia\n0\n1.00\nFALSE\n2\nYes: 419, No: 316\n\n\nItchyEye\n0\n1.00\nFALSE\n2\nNo: 553, Yes: 182\n\n\nNausea\n0\n1.00\nFALSE\n2\nNo: 477, Yes: 258\n\n\nEarPn\n0\n1.00\nFALSE\n2\nNo: 573, Yes: 162\n\n\nHearing\n0\n1.00\nFALSE\n2\nNo: 705, Yes: 30\n\n\nPharyngitis\n0\n1.00\nFALSE\n2\nYes: 614, No: 121\n\n\nBreathless\n0\n1.00\nFALSE\n2\nNo: 438, Yes: 297\n\n\nToothPn\n0\n1.00\nFALSE\n2\nNo: 569, Yes: 166\n\n\nVision\n0\n1.00\nFALSE\n2\nNo: 716, Yes: 19\n\n\nVomit\n0\n1.00\nFALSE\n2\nNo: 656, Yes: 79\n\n\nWheeze\n0\n1.00\nFALSE\n2\nNo: 514, Yes: 221\n\n\nRapidFluA\n407\n0.45\nFALSE\n2\nPos: 169, Pre: 159\n\n\nRapidFluB\n407\n0.45\nFALSE\n2\nPre: 302, Pos: 26\n\n\nPCRFluA\n581\n0.21\nFALSE\n3\nIn: 120, In: 33, Ind: 1, Ass: 0\n\n\nPCRFluB\n581\n0.21\nFALSE\n2\nIn: 145, In: 9, Ass: 0\n\n\nTransScore1F\n0\n1.00\nFALSE\n6\n4: 210, 5: 195, 3: 157, 2: 107\n\n\nTransScore2F\n0\n1.00\nFALSE\n5\n4: 294, 3: 201, 2: 138, 1: 89\n\n\nTransScore3F\n0\n1.00\nFALSE\n4\n3: 323, 2: 222, 1: 166, 0: 24\n\n\nTransScore4F\n0\n1.00\nFALSE\n5\n3: 230, 4: 198, 2: 154, 1: 103\n\n\nImpactScoreF\n0\n1.00\nFALSE\n17\n8: 105, 9: 104, 10: 88, 7: 84\n\n\nImpactScore2F\n0\n1.00\nFALSE\n16\n7: 107, 8: 102, 9: 90, 10: 86\n\n\nImpactScore3F\n0\n1.00\nFALSE\n14\n4: 134, 5: 112, 3: 108, 6: 102\n\n\nImpactScoreFD\n0\n1.00\nFALSE\n17\n8: 105, 9: 104, 10: 88, 7: 84\n\n\nTotalSymp1F\n0\n1.00\nFALSE\n19\n12: 86, 13: 84, 14: 80, 11: 72\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\nActivityLevel\n0\n1.00\n4.46\n2.64\n0.0\n3.0\n4.0\n6.0\n10.0\n▆▇▆▅▂\n\n\nBodyTemp\n5\n0.99\n98.94\n1.20\n97.2\n98.2\n98.5\n99.3\n103.1\n▇▇▂▁▁\n\n\nTransScore1\n0\n1.00\n3.47\n1.31\n0.0\n3.0\n4.0\n5.0\n5.0\n▂▅▆▇▇\n\n\nTransScore2\n0\n1.00\n2.92\n1.11\n0.0\n2.0\n3.0\n4.0\n4.0\n▁▂▃▆▇\n\n\nTransScore3\n0\n1.00\n2.15\n0.88\n0.0\n1.0\n2.0\n3.0\n3.0\n▁▅▁▆▇\n\n\nTransScore4\n0\n1.00\n2.58\n1.21\n0.0\n2.0\n3.0\n4.0\n4.0\n▂▃▆▇▇\n\n\nImpactScore\n0\n1.00\n9.51\n2.84\n2.0\n8.0\n9.0\n11.0\n18.0\n▂▇▇▅▁\n\n\nImpactScore2\n0\n1.00\n8.58\n2.78\n2.0\n7.0\n8.0\n10.0\n17.0\n▂▇▆▃▁\n\n\nImpactScore3\n0\n1.00\n5.06\n2.34\n0.0\n3.0\n5.0\n7.0\n13.0\n▂▇▃▂▁\n\n\nTotalSymp1\n0\n1.00\n12.99\n3.41\n5.0\n11.0\n13.0\n15.0\n23.0\n▂▇▇▅▁\n\n\nTotalSymp2\n0\n1.00\n12.43\n3.22\n4.0\n10.0\n12.0\n15.0\n22.0\n▁▇▇▅▁\n\n\nTotalSymp3\n0\n1.00\n11.66\n3.10\n3.0\n10.0\n12.0\n14.0\n21.0\n▁▇▇▅▁\n\n\n\n\n\nAfter viewing the data, I see there are 63 variables and 735 observations. Most are coded as factors and integers, and there is 1 character variable. Some variables have quite a good amount of NAs.\n\n\n\n\nsymptoms <- symptoms %>% select(9:40)\n\nSince all the variables of interest were all consecutive, I was able to easily select them based on their range of column number.\n\n\n\n\nsymptoms <- symptoms %>% na.omit()\n\nOnly 5 observations were removed, so it looks like we took care of most of the NAs when we selected for the relevant variables.\n\n\n\n\nsaveRDS(symptoms, here(\"fluanalysis/data/processed_data/symptoms_clean.RDS\"))"
  }
]